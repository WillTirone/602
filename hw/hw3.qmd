---
title: "STA 602 HW 3"
author: "William Tirone"
format: pdf
editor: visual
---

# 1 (3.3)

```{r}
yA = c(12, 9, 12, 14, 13, 13, 15, 8, 15, 6)
yB = c(11, 11, 10, 9, 9, 8, 7, 10, 6, 8, 8, 9, 7)
sum(yA)
sum(yB)
```

### a)

The below is possible because of independence of the priors. Thus, the posteriors are also independent since the priors and sampling models are independent as well.

$$
\begin{aligned}
p(\theta_A|y_1,...,y_{10}) &\propto p(\theta_A)p(y_1,...,y_{10}|\theta_A)\\
& =c(y,a,b) \times \theta^{121}e^{-10 \space \theta} \times \theta^{117}e^{-10\theta}\\
& = c(y,a,b) \times \theta^{238}e^{-20 \space \theta} \\
& \sim gamma(239,20)\\
mean & = 239 / 20 = 11.95 \\ 
var & = 239 / 400 = 0.5975
\\
\text{from the above we can generalize to: }\\
 p(\theta | y_1,...,y_n) & \sim gamma(a + \sum_{i=1}^{n}Y_i,b+n)\\
p(\theta_B|y_1,...,y_{13}) & \sim gamma(12 + 113, 1 + 13) = gamma(125,14)\\
mean&=125/14 = 8.93\\
var&=125/196 = 0.638
\end{aligned}
$$

```{r}
cat('95% Interval for GAM(237,20) : ', qgamma(.025,293,20), qgamma(.975,293,20))
```

```{r}
cat('95% Interval for GAM(125,14) : ', qgamma(.025,125,14), qgamma(.975,125,14))
```

### b)

DISCUSS PRIOR BELIEFS TO BE CLOSE TO THETA A

```{r}
# is posterior expectation just E(\theta | y)
n0 = seq(1,50,1)
yB = c(11, 11, 10, 9, 9, 8, 7, 10, 6, 8, 8, 9, 7)
n = length(yB)
sum_yB = sum(yB)
means = c() 

for (i in n0){
  
  # prior 
  alpha = 12 * i
  beta = i
  
  # posterior 
  posterior_alpha = alpha + sum_yB
  posterior_beta = beta + n 
  
  posterior_expectation = posterior_alpha / posterior_beta
  means = append(means,posterior_expectation)
  
}
```

```{r}
plot(n0,means,type='l',
    ylim=c(8.5,12.5),
    ylab='Posterior Expectations',
    col='blue')
abline(h=11.95 ,col='red')
text(10,9.5, "posterior")
text(20,12, "theta A")
```

### c)

*"Tumor count rates for type B mice are unknown, but type B mice are related to type A mice."* This seems to indicate that it does not make sense to have $p(\theta_A,\theta_B) = p(\theta_B) \times p(\theta_A)$ since that implies independence. So it seems like studies of the mice in group A could influence our priors for group B.

# 2 (3.5)

### a)

$$
\begin{aligned}
p(\phi | y_1,...,y_n) & \propto \tilde{p}(\phi)p(y_1,...,y_n | \phi) \\ 
iid & \propto \sum_{k=1}^{K}w_k p_k(\theta) \prod_{i=1}^{n}h(y_i)c(\phi)e^{\phi t(y_i)}\\
& \propto \sum_{k=1}^{K}w_k p_k(\theta) \sum_{i=1}^{n} h(y_i) c(\phi)^n \text{exp} \{ n \phi\sum_{i=1}^{n}y_i\}
\end{aligned}
$$

### b)

$$
\begin{aligned}
p(\phi | y_1,...,y_n) & \propto \tilde{p}(\phi)p(y_1,...,y_n | \phi) \\ 
iid & \propto \sum_{k=1}^{K}w_k p_k(\theta) \prod_{i=1}^{n}\frac{e^{\theta} \theta^{y_i}}{y_i!}\\
& \propto \sum_{k=1}^{K}w_k p_k(\theta) \frac{e^{n\theta} \theta^{\sum y_i}}{\sum y_i!}
\end{aligned}
$$

# 3 (3.8)

### a)

For the parameters, I assumed that we had previously observed 30 total flips. Thus, the expectation of the first part of the mixture is 1/3, the 20% portion is 1/2, and the last piece has an expectation of 2/3.

```{r}
thetas = seq(0,1,0.01)
#values = (.4 * dbeta(thetas,10,20)) +  (.2 * dbeta(thetas,15,15)) + (.4 * dbeta(thetas,20,10))
values = (.4 * dbeta(thetas,100,200)) +  (.2 * dbeta(thetas,150,150)) + (.4 * dbeta(thetas,200,100))
plot(thetas,values,type='l',col='blue')
```

### b)

U.S. Quarter, 2020, 27 heads, 23 tails

### c)

Compute posterior:

http://www.mas.ncl.ac.uk/\~nmf16/teaching/mas3301/week11.pdf

```{r}
# this is incorrect because the weights will sum up > 1 
posterior_c = dbeta(thetas,28,24) * values
plot(thetas,posterior_c,type='l')
```

### d)

# 4 (4.3)

example in 4.4

### a)

```{r}
a=2 
b=1

sy1 = 217
sy2 = 66

n1 = 10 # sample size 
n2 = 44

t.mc=NULL

for ( s in 1:1000) {
  
# theta1 is sample from the posterior, gam(239,20)
theta1 = rgamma(1,239,20) #samples from posterior

y1.mc = rpois(n1 , theta1) #dataset 

t.mc = c(t.mc,(sum(y1.mc) / 10) / sd(y1.mc))
}

df = as.data.frame(t.mc)
df %>% ggplot(aes(x=t.mc)) +
    geom_histogram(binwidth=0.25, fill="#A7C7E7",color='black',alpha=0.9)
```

### b)

# 5

### a)

### b)

### 

$$
\begin{aligned}
& 
& 
& 
& 
& 
\end{aligned}
$$
