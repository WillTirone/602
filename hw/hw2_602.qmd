---
title: "602_hw2"
author: "William Tirone"
format: pdf
editor: visual
---

# 3.1

a\)

$$
P(Y_1=y_1, \dots, Y_{100} = y_{100} | \theta) =\text{by independence} = \prod_{i=1}^{n} P(Y_i | \theta) = \prod_{i=1}^{n}\theta^{y_i}(1-\theta)^{1-y_i} =\\
\theta^{\Sigma_{i=1}^{n} {y_i}}( 1-\theta)^{100-\Sigma_{i=1}^{n}y_i} ;  y=0,1\\
$$

Finding the distribution of $P(\sum_{i=1}^{n}Y_i = y | \theta)$

$$
M_{\sum Y_i = y | \theta}(t) = \text{by independence} = \prod_{i=i}^{n}M_{Y_i|\theta}(t) = \\
\prod_{i=i}^{n}(1-p+pe^t) = (1-p+pe^t)^n = {n \choose x}\theta^x(1-\theta)^{n-x} = \\
{100 \choose 57}\theta^{57}(1-\theta)^{43}; \theta \in [0,1] \text{assuming a uniform prior?}
$$

b\)

```{r}
thetas = seq(0.0,1.0,by=0.1)
results = dbinom(57,100,thetas)

plot(thetas,results)
```

c\)

$$
p(\theta | \Sigma_{i=1}^{n}y_i = 57) = \frac{P(\Sigma_{i=1}^{n}y_i = 57 | \theta)P(\theta)}{P(\Sigma_{i=1}^{n}y_i = 57)}  \\
\text{each } P(\Theta = \theta) = \frac{1}{11}\\
\\
$$

sum function above \
may need to add binomial coefficient and sum out the discrete values of theta?

The posterior distribution and marginal distribution of Y are just scaling constants since the denominator does not depend on theta and we have equal belief for each of $P(\theta)$.

```{r}

marginal_y = sum((1/11) * dbinom(57,100,thetas))
posterior = (results * (1/11))/marginal_y
plot(thetas,posterior)
```

d\)

Not sure here on letting theta be any value in the interval. Approximating that with discrete values below but not sure if that's correct?

```{r}
thetas = seq(0,1,by=0.001) #U(0,1)
results = dbinom(57,100,thetas)
plot(thetas,results,type="l")
```

e\)

Same thing as d)

```{r}
plot(thetas,dbeta(thetas,58,44),type='l')
```

# 3.2

Looks almost correct here but some kind of calculation is off?

```{r}

theta0 = seq(0.1,0.9,by=0.1)
n0 = c(1,2,8,16,32)

data=c()

for (i in theta0) {
for (j in n0) {
  
    a = i * j
    b = (1-i)*j

    p = pbeta(.5,a+57,b+43,lower.tail=FALSE) #posterior (theta > .5 | sum = 57)
    data = append(data,p)

}
}

probability_data = matrix(data,nrow=9,ncol=5,byrow=TRUE)
contour(theta0,n0,probability_data, xlab="thetas",ylab='n0 values')
```

# 3.4

$$
p(\theta | y) = \frac{p(y|\theta)p(\theta)}{p(y)}
$$

a\)

calculations for posterior with prior beta(2,8) and beta(8,2) are here, with plots for part a) and part b) following this chunk.

```{r}
beta_mean = function(a,b){
  print("mean:")
  a / (a+b)
}

beta_mode = function(a,b){
  print('mode:')
  (a-1) / (a+b-2)
}

beta_sd = function(a,b){
  print('standard deviation:')
  var = (a*b) / ((a+b)^2 * (a+b+1))
  sd = sqrt(var)
  return(sd) 
}

CI_28 = c(qbeta(.025,17,36),qbeta(.975,17,36))
CI_82 = c(qbeta(.025,23,30),qbeta(.975,23,30))

#data for the posterior w/ 2,8 prior and posterior a = 17, posterior b = 36
print("using alpha = 17 and beta = 36 with beta(2,8) prior")
beta_mean(17,36)
beta_mode(17,36)
beta_sd(17,36)
print(c("95% CI",CI_28))

#with 8,2 prior 
print(" ")
print("================================================")
print("using alpha = 23, beta = 30 with beta(8,2) prior")
beta_mean(23,30)
beta_mode(23,30)
beta_sd(23,30)
print(c("95% CI",CI_82))
```

plots for part a)

```{r}
#plotting prior p(\theta)
thetas = seq(0,1,by=0.001) #U(0,1)

plot(thetas, dbeta(thetas, 2,8), type='l',main="p(theta)")

#plotting p(y=15|\theta)
#plot a binomial here 
plot(thetas, dbinom(15,43,thetas))

#posterior which is beta(2 + success, 8 + failure) = beta()
a=2+15
b=8+28
plot(thetas, dbeta(thetas,a,b),type='l',main="posterior model")
abline(v=beta_mean(a,b), col='red') #mean
abline(v=beta_mode(a,b), col='blue') #mode

# CI 
abline(v=qbeta(.975,a,b),col='green') #lower bound 
abline(v=qbeta(.025,a,b),col='green') #upper bound 
```

plots for part b)

```{r}

#plotting prior p(\theta)
thetas = seq(0,1,by=0.001) #U(0,1)

plot(thetas, dbeta(thetas, 8,2), type='l',main="p(theta)")

#plotting p(y=15|\theta)
#plot a binomial here 
plot(thetas, dbinom(15,43,thetas))

#posterior which is beta(2 + success, 8 + failure) = beta()
a=8+15
b=2+28
plot(thetas, dbeta(thetas,a,b),type='l',main="posterior model")
abline(v=beta_mean(a,b), col='red') #mean
abline(v=beta_mode(a,b), col='blue') #mode

# CI 
abline(v=qbeta(.975,a,b),col='green') #lower bound 
abline(v=qbeta(.025,a,b),col='green') #upper bound 
```

c\)

This may represent that you have about 25% confidence that there are going to be 8 cases of recidivism and 2 cases of not, while the beta(2,8) represents you're 75% confident that there will be 2 cases of recidivism and 8 cases of failure respectively. This is if you've only seen 10 prior cases.

Or maybe there were two previous studies with 2 successes and 8 failures or 2 failures and 8 successes respectively.

```{r}
prior = 0.75 * dbeta(thetas,2,8) + 0.25 * dbeta(thetas,8,2)
plot(thetas,prior,type="l")
```

d\) i)
$$
\begin{align}
p(\theta) * p(y|\theta) \\
= \frac{1}{4} \frac{\Gamma(10)}{\Gamma(2) \Gamma(8)} {43 \choose 15}[3 \theta^{16}(1-\theta^{35}) + \theta^{22}(1-\theta)^{25}]
\end{align}
$$

ii\) This is a mixture of $beta(17,36)$ and $beta(23,26)$

iii\) plot:
